{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "- Tensors are a data structure similar to arrays and matrices, in torch we use them to encode the inputs and outputs of a model, as well as the model's parameters\n",
    "- They are similar to ndarrays, but can run on GPUs, and are optimised for automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialise tensors in various ways, directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From another tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4268, 0.4204],\n",
      "        [0.5741, 0.5577]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f'Ones Tensor: \\n {x_ones} \\n')\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f'Random Tensor: \\n {x_rand} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1061, 0.4345, 0.1067],\n",
      "        [0.4661, 0.6964, 0.9460]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f'Shape of tensor: {tensor.shape}')\n",
    "print(f'Datatype of tensor: {tensor.dtype}')\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tensors are created on the CPU, we can move them to the GPU if cuda is available on the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor moved to GPU\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print('Tensor moved to GPU')\n",
    "else:\n",
    "    print('No GPU available, tensor remains on CPU')\n",
    "\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard numpy-like operations apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0.3831, 0.2075, 0.7678, 0.0966], device='cuda:0')\n",
      "First column: tensor([0.3831, 0.9010, 0.8896], device='cuda:0')\n",
      "tensor([[0.3831, 0.0000, 0.7678, 0.0966],\n",
      "        [0.9010, 0.0000, 0.6888, 0.6859],\n",
      "        [0.8896, 0.0000, 0.2968, 0.4025]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'First row: {tensor[0]}')\n",
    "print(f'First column: {tensor[:, 0]}')\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join tensors using `torch.cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3831, 0.0000, 0.7678, 0.0966, 0.3831, 0.0000, 0.7678, 0.0966, 0.3831,\n",
      "         0.0000, 0.7678, 0.0966],\n",
      "        [0.9010, 0.0000, 0.6888, 0.6859, 0.9010, 0.0000, 0.6888, 0.6859, 0.9010,\n",
      "         0.0000, 0.6888, 0.6859],\n",
      "        [0.8896, 0.0000, 0.2968, 0.4025, 0.8896, 0.0000, 0.2968, 0.4025, 0.8896,\n",
      "         0.0000, 0.2968, 0.4025]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply arithmetic operations, such as matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: tensor([[0.7455, 0.9402, 0.6075],\n",
      "        [0.9402, 1.7567, 1.2820],\n",
      "        [0.6075, 1.2820, 1.0415]], device='cuda:0')\n",
      "y2: tensor([[0.7455, 0.9402, 0.6075],\n",
      "        [0.9402, 1.7567, 1.2820],\n",
      "        [0.6075, 1.2820, 1.0415]], device='cuda:0')\n",
      "y2: tensor([[0.7455, 0.9402, 0.6075],\n",
      "        [0.9402, 1.7567, 1.2820],\n",
      "        [0.6075, 1.2820, 1.0415]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(f'y1: {y1}')\n",
    "print(f'y2: {y2}')\n",
    "print(f'y2: {y3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1: tensor([[0.1467, 0.0000, 0.5895, 0.0093],\n",
      "        [0.8118, 0.0000, 0.4745, 0.4704],\n",
      "        [0.7915, 0.0000, 0.0881, 0.1620]], device='cuda:0')\n",
      "z2: tensor([[0.1467, 0.0000, 0.5895, 0.0093],\n",
      "        [0.8118, 0.0000, 0.4745, 0.4704],\n",
      "        [0.7915, 0.0000, 0.0881, 0.1620]], device='cuda:0')\n",
      "z3: tensor([[0.1467, 0.0000, 0.5895, 0.0093],\n",
      "        [0.8118, 0.0000, 0.4745, 0.4704],\n",
      "        [0.7915, 0.0000, 0.0881, 0.1620]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(f'z1: {z1}')\n",
    "print(f'z2: {z2}')\n",
    "print(f'z3: {z3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single-element tensor can be converted into a python numerical value using `item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.112013816833496 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations are operations that store the result into the operand, and are denoted by a `_` suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3831, 0.0000, 0.7678, 0.0966],\n",
      "        [0.9010, 0.0000, 0.6888, 0.6859],\n",
      "        [0.8896, 0.0000, 0.2968, 0.4025]], device='cuda:0') \n",
      "\n",
      "tensor([[5.3831, 5.0000, 5.7678, 5.0966],\n",
      "        [5.9010, 5.0000, 5.6888, 5.6859],\n",
      "        [5.8896, 5.0000, 5.2968, 5.4025]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'{tensor} \\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In place operations save some memory, but can be problematic when computing derivatives beacuse of an immediate loss of history, so better not to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "We want our dataset code to be decoupled from our model training code for better readability and modularity.\n",
    "\n",
    "PyTorch provides two data primitives, `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. \n",
    "\n",
    "`Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples.\n",
    "\n",
    "### Loading a Dataset\n",
    "\n",
    "We will use the `Fashion-MNIST` dataset from TorchVision as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and Visualising the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\"\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom dataset for your files\n",
    "\n",
    "A custom Dataset class must implement three functions, `__init__`, `__len__`, and `__getitem__`.\n",
    "\n",
    "- `__init__` function is run when instantiating the Dataset object\n",
    "- `__len__` function returns the number of samples in our dataset\n",
    "- `__getitem__` function loads and returns a sample from the dataset at the given index `idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training with DataLoaders\n",
    "\n",
    "The Dataset retrieves our dataset's features and labels one sample at a time. While training a model, we typically want to pass samples in 'minibatches', reshuffle the data at every epoch to reduce model overfitting, and use Python's multiprocessing to speed up data retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_dataloader` is an iterable, each iteration returns a batch of `train_features` and `train_labels`.\n",
    "\n",
    "## Transforms\n",
    "Data does not always come in its final processed form that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training.\n",
    "\n",
    "All TorchVision datasets have two parameters - `transform` to modify the features, and `target_transform` to modify the labels.\n",
    "\n",
    "`torchvision.transforms` offers several commonly used transforms out of the box. \n",
    "\n",
    "The FashionMNIST features are in PIL image format, and the labels are integers. We need the features as normalised tensors, and the labels as one-hot encoded tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "\n",
    "Neural networks comprise of layers/modules that perform operations on data. The `torch.nn` namespace provides all the building blocks you need to build your own neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Device for Training\n",
    "\n",
    "Check if `torch.cuda` or `torch.backend.mps` are available, otherwise use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Class\n",
    "\n",
    "We define our neural networks by subclassing `nn.Module`, and initialising the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on imput data in the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the parent class\n",
    "        super().__init__()\n",
    "        # Convert the multidimensional input data into a flat vector\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Define a sequence of layers that will be applied in order\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    # Forward pass of the neural network\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model, we pass it the input data. This executes `forward`, along with some background operations. Don't call `model.forward` directly!\n",
    "\n",
    "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim1 corresponding to the individual values of each output.\n",
    "\n",
    "We get the prediction probabilities by passing it through an instance of the `nn.Softmax` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "\n",
    "print(f'Predicted class: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Layers\n",
    "\n",
    "Lets break down the layers in the FashionMNIST model. To illustrate it, we will take a sample minibatch of 3 images of size 28x28 and see what happens to it as we pass through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Flatten\n",
    "We initialise the `nn.Flatten` layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Linear\n",
    "\n",
    "Applies a linear transformation on the input using its stored weights and biases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ReLU\n",
    "\n",
    "Non-linear activations are what create the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce *nonlinearity*, helping neural networks learn a wide variety of phenomena. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.0122, -0.1563, -0.3748,  0.2833,  0.1371,  0.4365, -0.1422,  0.1406,\n",
      "         -0.4617,  0.3461,  0.0291, -0.5032,  0.2111,  0.4624, -0.1422, -0.9650,\n",
      "         -0.4828,  0.3105,  0.2090, -0.0825],\n",
      "        [ 0.0570,  0.1801, -0.0668, -0.2199, -0.1887,  0.3558, -0.0784,  0.0774,\n",
      "         -0.0133,  0.2147,  0.0849, -0.6314,  0.2247,  0.4968, -0.2722, -0.6856,\n",
      "         -0.3613,  0.2745,  0.1639,  0.3564],\n",
      "        [ 0.0508, -0.0383, -0.2446, -0.2077,  0.0045,  0.7524,  0.1269, -0.0858,\n",
      "         -0.1136,  0.0432,  0.0063, -0.3551,  0.3653,  0.3212, -0.3229, -0.8488,\n",
      "         -0.5072, -0.0078, -0.2196,  0.1127]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.2833, 0.1371, 0.4365, 0.0000, 0.1406, 0.0000,\n",
      "         0.3461, 0.0291, 0.0000, 0.2111, 0.4624, 0.0000, 0.0000, 0.0000, 0.3105,\n",
      "         0.2090, 0.0000],\n",
      "        [0.0570, 0.1801, 0.0000, 0.0000, 0.0000, 0.3558, 0.0000, 0.0774, 0.0000,\n",
      "         0.2147, 0.0849, 0.0000, 0.2247, 0.4968, 0.0000, 0.0000, 0.0000, 0.2745,\n",
      "         0.1639, 0.3564],\n",
      "        [0.0508, 0.0000, 0.0000, 0.0000, 0.0045, 0.7524, 0.1269, 0.0000, 0.0000,\n",
      "         0.0432, 0.0063, 0.0000, 0.3653, 0.3212, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1127]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Before ReLU: {hidden1}\\n\\n')\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f'After ReLU: {hidden1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Sequential\n",
    "\n",
    "An ordered container of modules. The data is passed through all the modules in the same order as defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Softmax\n",
    "\n",
    "The last linear layer of the nn returns logits - raw values in $(-\\inf, \\inf )$ whcih are passed to the `nn.Softmax` module. They are scaled to values $[1, 10]$ representing the modules predicted probabilities for each class. `dim` parameters indicate the the dimension along which the values must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "\n",
    "Many layers inside a neural network are parameterised, i.e. have associated weights and biases that are optimised during training. Subclassing `nn.Module` automatically tracks all fields defined inside your model object, and makes all parameters accesible using your model's `parameters()` or `named_parameters()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0336, -0.0308,  0.0102,  ...,  0.0075,  0.0252,  0.0338],\n",
      "        [ 0.0300, -0.0332, -0.0319,  ...,  0.0160,  0.0347,  0.0057]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([ 0.0165, -0.0007], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0426, -0.0055, -0.0256,  ..., -0.0396, -0.0243, -0.0113],\n",
      "        [ 0.0137, -0.0153,  0.0105,  ...,  0.0157, -0.0111,  0.0137]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([ 0.0087, -0.0224], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0092, -0.0366,  0.0262,  ..., -0.0076,  0.0284, -0.0364],\n",
      "        [ 0.0097, -0.0182,  0.0357,  ...,  0.0009,  0.0412, -0.0435]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0376, -0.0101], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Model Structure: {model}\\n\\n')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation with `torch.autograd`\n",
    "\n",
    "When training neural networks, the most frequently used algorithm is *back propagation*. Model weights are adjusted according to the gradient of the loss function wrt the given parameter.\n",
    "\n",
    "To compute these gradients, PyTorch has a built-in differentiation engine called `torch-autograd`. It supports automatic computation of gradient for any computation graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5) # input tensor\n",
    "y = torch.zeros(3) # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x0000025564411E40>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x00000255633ED930>\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradient function for z = {z.grad_fn}')\n",
    "print(f'Gradient function for loss = {loss.grad_fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients\n",
    "\n",
    "To optimise weights, we need to compute derivatives of our loss function with respect to parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0006, 0.2967, 0.0180],\n",
      "        [0.0006, 0.2967, 0.0180],\n",
      "        [0.0006, 0.2967, 0.0180],\n",
      "        [0.0006, 0.2967, 0.0180],\n",
      "        [0.0006, 0.2967, 0.0180]])\n",
      "tensor([0.0006, 0.2967, 0.0180])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disabling Gradient Tracking\n",
    "\n",
    "By default, all tensors with requires_grad=True are tracking their computational history and support gradient computation. However, there are some cases when we do not need to do that, e.g., when we have trained the model and just want to apply it to some input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising Model Parameters\n",
    "\n",
    "Now that we have a model and data, it's time to train, validate, and test out model. This is an iterative process; in each iteration the model makes a geuss about the output, calculates the error in its guess (loss), collects the derivatives of the error with respect to its parameters, and optimises those parameters using gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the previous code\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Adjustable parameters that let you control the model optimisation process. Different hyperparameter values can impact model training and convergence rates.\n",
    "\n",
    "We define three hyperparameters for training:\n",
    "- **Number of Epochs** - the number of times to iterate over the dataset\n",
    "- **Batch Size** - the number of data samples propagated through the network before the parameters are updated\n",
    "- **Learning Rate** - how much to update model parameters at each batch/epoch. Smaller values yield slow learning speed, whilst large values may result in unpredictable behaviour during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation Loop\n",
    "\n",
    "Once we set our hyperparameters, we can then train and optimise our model with an optimisation loop. Each iteration of the optimisation loop is called an epoch.\n",
    "\n",
    "Each epoch consists of two main parts:\n",
    "- **The Train Loop** - iterate over the training dataset and try to converge to optimal parameters\n",
    "- **The Validation Test**  - iterate over the test dataset to check if model performance is improving\n",
    "\n",
    "#### Loss Function\n",
    "Measures the degree of dissimilarity of obtained result to the target value, we want to minimise this during training. \n",
    "\n",
    "Some common loss functions are\n",
    "- `nn.MSElLoss` (Mean Square Error) for regression tasks\n",
    "- `nn.NLLLoss` (Negative Log Likelihood) for classification\n",
    "- `nn.CrossEntropyLoss` combines `nn.LogSoftmax` and `nn.NLLLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimiser\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is the optimisation algorithm we choose to use here. There are many different options available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the optimiser\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the training loop, optimisation happens in three steps:\n",
    "- Call `optimiser.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitely zero them at each iteration\n",
    "- Backpropagate the prediction loss with a call to `loss.backward()`\n",
    "- Once we have our gradients, call `optimiser.step()` to adjust the parameters by the gradients collected in the backward pass. \n",
    "\n",
    "### Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimiser):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Set the model to rtaining mode - important for batch normalisation and dropout layers\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Move data to the appropriate device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d} / {size:>5d}]')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Ensure no gradients are computed during test mode\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Move data to the appropriate device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f'Test Error: \\n Accuracy: {100*correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----------------------------------------\n",
      "loss: 2.163063 [   64 / 60000]\n",
      "loss: 2.153324 [ 6464 / 60000]\n",
      "loss: 2.095211 [12864 / 60000]\n",
      "loss: 2.115778 [19264 / 60000]\n",
      "loss: 2.058403 [25664 / 60000]\n",
      "loss: 1.989292 [32064 / 60000]\n",
      "loss: 2.027924 [38464 / 60000]\n",
      "loss: 1.934805 [44864 / 60000]\n",
      "loss: 1.955575 [51264 / 60000]\n",
      "loss: 1.875955 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 1.876890 \n",
      "\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "loss: 1.917874 [   64 / 60000]\n",
      "loss: 1.880631 [ 6464 / 60000]\n",
      "loss: 1.766877 [12864 / 60000]\n",
      "loss: 1.813779 [19264 / 60000]\n",
      "loss: 1.695910 [25664 / 60000]\n",
      "loss: 1.649460 [32064 / 60000]\n",
      "loss: 1.676372 [38464 / 60000]\n",
      "loss: 1.570293 [44864 / 60000]\n",
      "loss: 1.608298 [51264 / 60000]\n",
      "loss: 1.500020 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.516606 \n",
      "\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "loss: 1.593042 [   64 / 60000]\n",
      "loss: 1.547595 [ 6464 / 60000]\n",
      "loss: 1.404408 [12864 / 60000]\n",
      "loss: 1.476381 [19264 / 60000]\n",
      "loss: 1.352938 [25664 / 60000]\n",
      "loss: 1.354587 [32064 / 60000]\n",
      "loss: 1.366504 [38464 / 60000]\n",
      "loss: 1.286838 [44864 / 60000]\n",
      "loss: 1.331530 [51264 / 60000]\n",
      "loss: 1.232615 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.254475 \n",
      "\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "loss: 1.339499 [   64 / 60000]\n",
      "loss: 1.311679 [ 6464 / 60000]\n",
      "loss: 1.153704 [12864 / 60000]\n",
      "loss: 1.258702 [19264 / 60000]\n",
      "loss: 1.126494 [25664 / 60000]\n",
      "loss: 1.157110 [32064 / 60000]\n",
      "loss: 1.174255 [38464 / 60000]\n",
      "loss: 1.107339 [44864 / 60000]\n",
      "loss: 1.158391 [51264 / 60000]\n",
      "loss: 1.074919 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.091348 \n",
      "\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "loss: 1.167853 [   64 / 60000]\n",
      "loss: 1.160904 [ 6464 / 60000]\n",
      "loss: 0.988488 [12864 / 60000]\n",
      "loss: 1.124312 [19264 / 60000]\n",
      "loss: 0.986940 [25664 / 60000]\n",
      "loss: 1.024409 [32064 / 60000]\n",
      "loss: 1.054961 [38464 / 60000]\n",
      "loss: 0.993223 [44864 / 60000]\n",
      "loss: 1.046517 [51264 / 60000]\n",
      "loss: 0.975367 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.986010 \n",
      "\n",
      "Epoch 6\n",
      "----------------------------------------\n",
      "loss: 1.048862 [   64 / 60000]\n",
      "loss: 1.062493 [ 6464 / 60000]\n",
      "loss: 0.875587 [12864 / 60000]\n",
      "loss: 1.034514 [19264 / 60000]\n",
      "loss: 0.898601 [25664 / 60000]\n",
      "loss: 0.930513 [32064 / 60000]\n",
      "loss: 0.976317 [38464 / 60000]\n",
      "loss: 0.918726 [44864 / 60000]\n",
      "loss: 0.968992 [51264 / 60000]\n",
      "loss: 0.907610 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.913749 \n",
      "\n",
      "Epoch 7\n",
      "----------------------------------------\n",
      "loss: 0.961039 [   64 / 60000]\n",
      "loss: 0.993245 [ 6464 / 60000]\n",
      "loss: 0.794236 [12864 / 60000]\n",
      "loss: 0.970171 [19264 / 60000]\n",
      "loss: 0.839237 [25664 / 60000]\n",
      "loss: 0.861109 [32064 / 60000]\n",
      "loss: 0.920528 [38464 / 60000]\n",
      "loss: 0.868334 [44864 / 60000]\n",
      "loss: 0.912917 [51264 / 60000]\n",
      "loss: 0.858154 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.861281 \n",
      "\n",
      "Epoch 8\n",
      "----------------------------------------\n",
      "loss: 0.893294 [   64 / 60000]\n",
      "loss: 0.941002 [ 6464 / 60000]\n",
      "loss: 0.733194 [12864 / 60000]\n",
      "loss: 0.921414 [19264 / 60000]\n",
      "loss: 0.796849 [25664 / 60000]\n",
      "loss: 0.808244 [32064 / 60000]\n",
      "loss: 0.877961 [38464 / 60000]\n",
      "loss: 0.832784 [44864 / 60000]\n",
      "loss: 0.870482 [51264 / 60000]\n",
      "loss: 0.819773 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.821214 \n",
      "\n",
      "Epoch 9\n",
      "----------------------------------------\n",
      "loss: 0.838592 [   64 / 60000]\n",
      "loss: 0.899043 [ 6464 / 60000]\n",
      "loss: 0.685466 [12864 / 60000]\n",
      "loss: 0.883092 [19264 / 60000]\n",
      "loss: 0.764988 [25664 / 60000]\n",
      "loss: 0.767335 [32064 / 60000]\n",
      "loss: 0.843391 [38464 / 60000]\n",
      "loss: 0.806406 [44864 / 60000]\n",
      "loss: 0.837443 [51264 / 60000]\n",
      "loss: 0.788635 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.789346 \n",
      "\n",
      "Epoch 10\n",
      "----------------------------------------\n",
      "loss: 0.793026 [   64 / 60000]\n",
      "loss: 0.863530 [ 6464 / 60000]\n",
      "loss: 0.646939 [12864 / 60000]\n",
      "loss: 0.852184 [19264 / 60000]\n",
      "loss: 0.739681 [25664 / 60000]\n",
      "loss: 0.735252 [32064 / 60000]\n",
      "loss: 0.813978 [38464 / 60000]\n",
      "loss: 0.785695 [44864 / 60000]\n",
      "loss: 0.810838 [51264 / 60000]\n",
      "loss: 0.762665 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.762977 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}')\n",
    "    print('-'*40)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimiser)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load the Model\n",
    "\n",
    "We can save the optimised weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load model weights, you need to create an instance of the same model first, then use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = NeuralNetwork()\n",
    "trained_model.load_state_dict(torch.load('model_weights.pth'))\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the structure of the model class together with the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_2 = torch.load('model.pth')\n",
    "trained_model_2.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
